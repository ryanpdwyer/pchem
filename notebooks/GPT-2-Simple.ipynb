{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Downloading 124M model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 377Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 4.94Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 470Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:21, 23.4Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 438Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 7.12Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 6.10Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import requests\n",
    "\n",
    "model_name = \"124M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "\tprint(f\"Downloading {model_name} model...\")\n",
    "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dwyerry/.local/lib/python3.7/site-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 73.45] loss=4.10 avg=4.10\n",
      "[2 | 128.62] loss=3.78 avg=3.94\n",
      "[3 | 182.44] loss=3.65 avg=3.84\n",
      "[4 | 235.95] loss=3.53 avg=3.76\n",
      "[5 | 292.54] loss=3.69 avg=3.75\n",
      "[6 | 349.23] loss=3.82 avg=3.76\n",
      "[7 | 402.63] loss=3.62 avg=3.74\n",
      "[8 | 455.00] loss=3.77 avg=3.74\n",
      "[9 | 509.39] loss=3.81 avg=3.75\n",
      "[10 | 564.14] loss=3.57 avg=3.73\n",
      "[11 | 619.03] loss=3.33 avg=3.69\n",
      "[12 | 672.35] loss=3.64 avg=3.69\n",
      "[13 | 726.60] loss=3.50 avg=3.67\n",
      "[14 | 782.14] loss=3.46 avg=3.66\n",
      "[15 | 836.63] loss=3.50 avg=3.65\n",
      "[16 | 891.05] loss=3.59 avg=3.64\n",
      "[17 | 945.39] loss=3.51 avg=3.63\n",
      "[18 | 999.95] loss=3.67 avg=3.64\n",
      "[19 | 1055.66] loss=3.77 avg=3.64\n",
      "[20 | 1112.81] loss=3.80 avg=3.65\n",
      "[21 | 1165.95] loss=3.47 avg=3.64\n",
      "[22 | 1230.31] loss=3.48 avg=3.63\n",
      "[23 | 1294.94] loss=3.60 avg=3.63\n",
      "[24 | 1361.32] loss=3.16 avg=3.61\n",
      "[25 | 8626.93] loss=3.37 avg=3.60\n"
     ]
    }
   ],
   "source": [
    "file_name = \"shakespeare.txt\"\n",
    "if not os.path.isfile(file_name):\n",
    "\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "\tdata = requests.get(url)\n",
    "\t\n",
    "\twith open(file_name, 'w') as f:\n",
    "\t\tf.write(data.text)\n",
    "    \n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              file_name,\n",
    "              model_name=model_name,\n",
    "              steps=1000)   # steps is max number of training steps\n",
    "\n",
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
